{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a first attempt without splitting train/val/test and overfitting analysis.\n",
    "\n",
    "### 1. Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from dpk import koopman_probabilistic, model_objs\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data manipulation\n",
    "\n",
    "1. read the data\n",
    "2. rescale the data\n",
    "3. create fixed dt time vector\n",
    "3. make new data array with NaNs for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1: read data\n",
    "ff = glob.glob(\"../data/DVV/*ADO*\")[0]\n",
    "pd_dv = pd.read_csv(ff)\n",
    "pd_dv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: data rescaling\n",
    "crap=pd_dv['DVV']\n",
    "Yraw = crap.to_numpy().reshape(-1, 1)\n",
    "scale = np.std(Yraw)\n",
    "loc = np.mean(Yraw)\n",
    "Y = (Yraw - loc) / scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: time vector\n",
    "#Convert pandas datetime into numpy timestamp\n",
    "dates = np.array(pd.to_datetime(pd_dv['DATE']))\n",
    "tt = (pd.to_datetime(pd_dv['DATE']).values.astype(np.int64) // 10 ** 9 // 86400) # array of time stamps in seconds, but these are sampled each 10 day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the new data and fill with NaNs for the missing data points\n",
    "# x = pd.date_range(min(dates),periods=20*365,freq=\"D\")\n",
    "# x = x[x<max(dates)] # until the last\n",
    "# # print(max(dates))\n",
    "# xx= pd.to_datetime(x).values.astype(np.int64) // 10 ** 9 // 86400 \n",
    "\n",
    "\n",
    "# crap1=(tt[-1]*86400*10**9).astype('<M8[ns]')\n",
    "# print(crap1)\n",
    "\n",
    "\n",
    "\n",
    "# crap2=(xx[-1]*86400*10**9).astype('<M8[ns]')\n",
    "# print(crap2)\n",
    "\n",
    "# print(crap1<crap2)\n",
    "\n",
    "# print( pd.to_datetime(t[-1]*86400*10**9).values.astype(np.datetime)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now fill the data gap\n",
    "# YY = np.zeros(len(xx),dtype=np.float)\n",
    "# YY.fill(np.nan)\n",
    "# for ii,iy in enumerate(xx): # loop from the ideal time stamp in days\n",
    "#     ik=np.where(tt==iy)[0]\n",
    "#     if ik>0:\n",
    "#         YY[ii]=Y[ik[0]][0]\n",
    "# print(YY[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "ax.plot_date(dates,Y)\n",
    "# ax.plot_date(x,YY)\n",
    "ax.set_title('ADO')\n",
    "xx=plt.xticks(rotation=50)\n",
    "fmt_half_year = mdates.YearLocator()\n",
    "ax.xaxis.set_major_locator(fmt_half_year)\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "# ax.set_yticks([0])\n",
    "# ax.set_yticklabels(['dv/v'])\n",
    "ax.grid(True)\n",
    "# plt.plot(np.arange(len(pd_dv['DVV'])),pd_dv['DVV']);plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664b0e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y)\n",
    "print(np.any(np.isnan(Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with evenly spaced data\n",
    "fill in gaps just to make it a better dv/v time series\n",
    "oversample it to test the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate data, maybe it's missing data points? let's try one hour time sample\n",
    "from scipy.interpolate import interp1d\n",
    "%matplotlib inline\n",
    "tt = (pd.to_datetime(pd_dv['DATE']).values.astype(np.int64) // 10 ** 9 // 86400) # array of time stamps in days for the original data\n",
    "tt_h = (pd.to_datetime(pd_dv['DATE']).values.astype(np.int64) // 10 ** 9 // 3600) # array of time stamps in days for the original data\n",
    "x = pd.date_range(min(dates),periods=22*365*24,freq=\"H\")# new \"dates\" but sampled per hour\n",
    "x = x[x<max(dates)] # until the last day of record.\n",
    "xx= pd.to_datetime(x).values.astype(np.int64) // 10 ** 9 // 3600 # convert new array to time stamp, 1 index per hour\n",
    "crap1=np.zeros(len(tt_h))\n",
    "crap2=np.zeros(len(tt_h))\n",
    "crap1[:] = np.array(tt_h)\n",
    "for i in range(len(tt_h)):\n",
    "    crap2[i]=Y[i]\n",
    "crap3 = interp1d(crap1,crap2)\n",
    "Ynew = crap3(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale data\n",
    "Ynew=Ynew.reshape(-1,1)\n",
    "scale = np.std(Ynew)\n",
    "loc = np.mean(Ynew)\n",
    "Ynew2 = (Ynew - loc) / scale\n",
    "\n",
    "print(np.any(np.isnan(Ynew2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019a6c8f",
   "metadata": {},
   "source": [
    "### NOTE to Nicholas ###\n",
    "\n",
    "Below you can vary periods. They are made with a time stamp of 1 hour, 365x24 is 1 year period. 365x24x6 is 6 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a model:\n",
    "\n",
    "periods = [365*24,365*24*6]  # 1 year of time period, in hourly units\n",
    "model_obj = model_objs.NormalNLL(x_dim=Ynew2.shape[1], num_freqs=len(periods), num_covariates=1)\n",
    "print(model_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8100546d",
   "metadata": {},
   "source": [
    "## NOTE to Nicholas\n",
    "\n",
    "Apparently, we wrote 1 year ago changing ``weight_decay`` handled overfitting. Change to see what behavior it gives to the fit. Marine will need to figoure out why the learning rate affects overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcca25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(periods)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "k = koopman_probabilistic.KoopmanProb(model_obj, device='cpu')\n",
    "k.init_periods(periods)\n",
    "k.fit(Ynew2, covariates=np.arange(Ynew2.shape[0]).reshape(-1, 1), iterations=20, weight_decay=1e-4, verbose=True) # avoid overfitting with weight_decay = 1e-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICT and rescale data\n",
    "params = k.predict(T=30*365*24, covariates=np.arange(30*365*24).reshape(-1, 1))\n",
    "params = model_obj.rescale(loc, scale, params)\n",
    "loc_hat, scale_hat = params\n",
    "x_hat = model_obj.mean(params)\n",
    "std_hat = model_obj.std(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# make time vector of predictios\n",
    "T2=pd.date_range(min(dates),periods=30*365*24,freq=\"H\")#.to_pydatetime()\n",
    "\n",
    "# plot\n",
    "\n",
    "ax=plt.figure(figsize=(16,8))\n",
    "plt.plot_date(x,Ynew2, \"tab:blue\", label=\"$x$\")\n",
    "plt.plot_date(T2,x_hat, \"tab:orange\", label=\"$\\hat x$\")\n",
    "plt.plot_date(T2,x_hat + std_hat, \"--k\", label=\"$\\hat x \\pm \\hat \\sigma$\")\n",
    "plt.plot_date(T2,x_hat - std_hat, \"--k\")\n",
    "# plt.xlim([1_000, 200_000])\n",
    "# ax.set_ylim([-5,5])\n",
    "plt.legend()\n",
    "plt.xlabel('Date (years)')\n",
    "plt.title('ADO')\n",
    "plt.ylabel('dv/v (%)')\n",
    "plt.grid(True)\n",
    "plt.savefig('test_ADO.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "ax=plt.figure(figsize=(16,8))\n",
    "plt.plot(Ynew-x_hat[:len(x)], \"tab:orange\", label=\"$\\hat x$\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(x_hat)\n",
    "# plt.plot(x_hat)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "inpt = torch.cat([torch.zeros((10000,4)),torch.linspace(0,1,10000)[:,None]],-1)\n",
    "inpt = torch.cat([inpt,inpt,inpt], -1)\n",
    "outp = k.model_obj.decode(inpt)[1].detach().numpy()\n",
    "plt.plot(outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5e7ecd2de5a212ea1e98fea463f222096989c3dc5c69aa836bc16767950ca34d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
